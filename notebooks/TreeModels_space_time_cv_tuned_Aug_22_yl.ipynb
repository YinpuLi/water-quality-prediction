{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error,mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "To make valid comparison across different methods, we split the original `stack_train` into new train and validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "\n",
    "y_train = pd.read_csv(get_absolute_path('y_train.csv', 'data'))\n",
    "y_test  = pd.read_csv(get_absolute_path('y_test.csv', 'data'))\n",
    "\n",
    "\n",
    "stack_train = pd.read_csv(get_absolute_path('stacked_X_tr.csv', 'data'))\n",
    "stack_test  = pd.read_csv(get_absolute_path('stacked_X_te.csv', 'data'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = convert_season_to_numeric(stack_train)\n",
    "stack_test = convert_season_to_numeric(stack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)',\n",
       "       'pH, water, unfiltered, field, standard units (Maximum)',\n",
       "       'pH, water, unfiltered, field, standard units (Minimum)',\n",
       "       'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)',\n",
       "       'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)',\n",
       "       'Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)',\n",
       "       'Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)',\n",
       "       'Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)',\n",
       "       'Temperature, water, degrees Celsius (Mean)',\n",
       "       'Temperature, water, degrees Celsius (Minimum)',\n",
       "       'Temperature, water, degrees Celsius (Maximum)', 'Date', 'Location_ID',\n",
       "       'Month', 'Week', 'Weekday', 'Season', 'Season_Num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)',\n",
       "       'pH, water, unfiltered, field, standard units (Maximum)',\n",
       "       'pH, water, unfiltered, field, standard units (Minimum)',\n",
       "       'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)',\n",
       "       'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)',\n",
       "       'Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)',\n",
       "       'Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)',\n",
       "       'Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)',\n",
       "       'Temperature, water, degrees Celsius (Mean)',\n",
       "       'Temperature, water, degrees Celsius (Minimum)',\n",
       "       'Temperature, water, degrees Celsius (Maximum)', 'Date', 'Location_ID',\n",
       "       'Month', 'Week', 'Weekday', 'Season', 'Season_Num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)</th>\n",
       "      <th>pH, water, unfiltered, field, standard units (Maximum)</th>\n",
       "      <th>pH, water, unfiltered, field, standard units (Minimum)</th>\n",
       "      <th>Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)</th>\n",
       "      <th>Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)</th>\n",
       "      <th>Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)</th>\n",
       "      <th>Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)</th>\n",
       "      <th>Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)</th>\n",
       "      <th>Temperature, water, degrees Celsius (Mean)</th>\n",
       "      <th>Temperature, water, degrees Celsius (Minimum)</th>\n",
       "      <th>Temperature, water, degrees Celsius (Maximum)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Season</th>\n",
       "      <th>Season_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.677632</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.765152</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>0.276163</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2198840.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.703947</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.301282</td>\n",
       "      <td>0.276163</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2198920.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.677632</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>0.287791</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2198950.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2203603.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088109</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.765152</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.281977</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2203655.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)   \n",
       "0                                           0.001131                                                     \\\n",
       "1                                           0.001170                                                      \n",
       "2                                           0.001326                                                      \n",
       "3                                           0.014094                                                      \n",
       "4                                           0.088109                                                      \n",
       "\n",
       "   pH, water, unfiltered, field, standard units (Maximum)   \n",
       "0                                           0.884615       \\\n",
       "1                                           0.871795        \n",
       "2                                           0.884615        \n",
       "3                                           0.858974        \n",
       "4                                           0.858974        \n",
       "\n",
       "   pH, water, unfiltered, field, standard units (Minimum)   \n",
       "0                                           0.001120       \\\n",
       "1                                           0.001159        \n",
       "2                                           0.001198        \n",
       "3                                           0.001238        \n",
       "4                                           0.010766        \n",
       "\n",
       "   Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)   \n",
       "0                                           0.001113                                                     \\\n",
       "1                                           0.001152                                                      \n",
       "2                                           0.001250                                                      \n",
       "3                                           0.003926                                                      \n",
       "4                                           0.029297                                                      \n",
       "\n",
       "   Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)   \n",
       "0                                           0.677632                                                  \\\n",
       "1                                           0.703947                                                   \n",
       "2                                           0.677632                                                   \n",
       "3                                           0.697368                                                   \n",
       "4                                           0.684211                                                   \n",
       "\n",
       "   Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)   \n",
       "0                                           0.841463                    \\\n",
       "1                                           0.829268                     \n",
       "2                                           0.853659                     \n",
       "3                                           0.829268                     \n",
       "4                                           0.853659                     \n",
       "\n",
       "   Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)   \n",
       "0                                           0.765152                 \\\n",
       "1                                           0.772727                  \n",
       "2                                           0.750000                  \n",
       "3                                           0.772727                  \n",
       "4                                           0.765152                  \n",
       "\n",
       "   Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)   \n",
       "0                                           0.787402                    \\\n",
       "1                                           0.795276                     \n",
       "2                                           0.755906                     \n",
       "3                                           0.771654                     \n",
       "4                                           0.755906                     \n",
       "\n",
       "   Temperature, water, degrees Celsius (Mean)   \n",
       "0                                    0.293750  \\\n",
       "1                                    0.293750   \n",
       "2                                    0.300000   \n",
       "3                                    0.296875   \n",
       "4                                    0.296875   \n",
       "\n",
       "   Temperature, water, degrees Celsius (Minimum)   \n",
       "0                                       0.298077  \\\n",
       "1                                       0.301282   \n",
       "2                                       0.298077   \n",
       "3                                       0.294872   \n",
       "4                                       0.291667   \n",
       "\n",
       "   Temperature, water, degrees Celsius (Maximum)        Date  Location_ID   \n",
       "0                                       0.276163  2016-01-28    2198840.0  \\\n",
       "1                                       0.276163  2016-01-28    2198920.0   \n",
       "2                                       0.287791  2016-01-28    2198950.0   \n",
       "3                                       0.279070  2016-01-28    2203603.0   \n",
       "4                                       0.281977  2016-01-28    2203655.0   \n",
       "\n",
       "   Month  Week  Weekday  Season  Season_Num  \n",
       "0      1     4        3  Winter           4  \n",
       "1      1     4        3  Winter           4  \n",
       "2      1     4        3  Winter           4  \n",
       "3      1     4        3  Winter           4  \n",
       "4      1     4        3  Winter           4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = stack_train.astype(column_data_extended_types)\n",
    "stack_test = stack_test.astype(column_data_extended_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)</th>\n",
       "      <th>pH, water, unfiltered, field, standard units (Maximum)</th>\n",
       "      <th>pH, water, unfiltered, field, standard units (Minimum)</th>\n",
       "      <th>Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)</th>\n",
       "      <th>Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)</th>\n",
       "      <th>Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)</th>\n",
       "      <th>Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)</th>\n",
       "      <th>Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)</th>\n",
       "      <th>Temperature, water, degrees Celsius (Mean)</th>\n",
       "      <th>Temperature, water, degrees Celsius (Minimum)</th>\n",
       "      <th>Temperature, water, degrees Celsius (Maximum)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Season</th>\n",
       "      <th>Season_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.677632</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.765152</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>0.276163</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2198840.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.703947</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.301282</td>\n",
       "      <td>0.276163</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2198920.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.677632</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>0.287791</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2198950.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2203603.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088109</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.765152</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.281977</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>2203655.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)   \n",
       "0                                           0.001131                                                     \\\n",
       "1                                           0.001170                                                      \n",
       "2                                           0.001326                                                      \n",
       "3                                           0.014094                                                      \n",
       "4                                           0.088109                                                      \n",
       "\n",
       "   pH, water, unfiltered, field, standard units (Maximum)   \n",
       "0                                           0.884615       \\\n",
       "1                                           0.871795        \n",
       "2                                           0.884615        \n",
       "3                                           0.858974        \n",
       "4                                           0.858974        \n",
       "\n",
       "   pH, water, unfiltered, field, standard units (Minimum)   \n",
       "0                                           0.001120       \\\n",
       "1                                           0.001159        \n",
       "2                                           0.001198        \n",
       "3                                           0.001238        \n",
       "4                                           0.010766        \n",
       "\n",
       "   Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)   \n",
       "0                                           0.001113                                                     \\\n",
       "1                                           0.001152                                                      \n",
       "2                                           0.001250                                                      \n",
       "3                                           0.003926                                                      \n",
       "4                                           0.029297                                                      \n",
       "\n",
       "   Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)   \n",
       "0                                           0.677632                                                  \\\n",
       "1                                           0.703947                                                   \n",
       "2                                           0.677632                                                   \n",
       "3                                           0.697368                                                   \n",
       "4                                           0.684211                                                   \n",
       "\n",
       "   Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)   \n",
       "0                                           0.841463                    \\\n",
       "1                                           0.829268                     \n",
       "2                                           0.853659                     \n",
       "3                                           0.829268                     \n",
       "4                                           0.853659                     \n",
       "\n",
       "   Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)   \n",
       "0                                           0.765152                 \\\n",
       "1                                           0.772727                  \n",
       "2                                           0.750000                  \n",
       "3                                           0.772727                  \n",
       "4                                           0.765152                  \n",
       "\n",
       "   Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)   \n",
       "0                                           0.787402                    \\\n",
       "1                                           0.795276                     \n",
       "2                                           0.755906                     \n",
       "3                                           0.771654                     \n",
       "4                                           0.755906                     \n",
       "\n",
       "   Temperature, water, degrees Celsius (Mean)   \n",
       "0                                    0.293750  \\\n",
       "1                                    0.293750   \n",
       "2                                    0.300000   \n",
       "3                                    0.296875   \n",
       "4                                    0.296875   \n",
       "\n",
       "   Temperature, water, degrees Celsius (Minimum)   \n",
       "0                                       0.298077  \\\n",
       "1                                       0.301282   \n",
       "2                                       0.298077   \n",
       "3                                       0.294872   \n",
       "4                                       0.291667   \n",
       "\n",
       "   Temperature, water, degrees Celsius (Maximum)        Date Location_ID   \n",
       "0                                       0.276163  2016-01-28   2198840.0  \\\n",
       "1                                       0.276163  2016-01-28   2198920.0   \n",
       "2                                       0.287791  2016-01-28   2198950.0   \n",
       "3                                       0.279070  2016-01-28   2203603.0   \n",
       "4                                       0.281977  2016-01-28   2203655.0   \n",
       "\n",
       "  Month Week Weekday  Season  Season_Num  \n",
       "0     1    4       3  Winter           4  \n",
       "1     1    4       3  Winter           4  \n",
       "2     1    4       3  Winter           4  \n",
       "3     1    4       3  Winter           4  \n",
       "4     1    4       3  Winter           4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric and categorical columns\n",
    "numeric_columns = stack_train.select_dtypes(include=['float64']).columns\n",
    "categorical_columns = [#'Date', \n",
    "                       'Location_ID',\n",
    "                    #    'Year',\n",
    "                       'Month',\n",
    "                       'Week',\n",
    "                       'Weekday',\n",
    "                       'Season'\n",
    "                       ]  # Add any categorical columns here\n",
    "\n",
    "# Create preprocessing transformers\n",
    "numeric_transformer = StandardScaler()  # we can use other scalers as well\n",
    "categorical_transformer = OneHotEncoder(drop=None)  # Use one-hot encoding for categorical columns\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on training data and transform both train and test data\n",
    "X_train_preprocessed = preprocessor.fit_transform(stack_train)\n",
    "X_test_preprocessed  = preprocessor.transform(stack_test)\n",
    "\n",
    "\n",
    "# Get the column names after one-hot encoding\n",
    "categorical_encoded_columns = preprocessor.named_transformers_['cat']\\\n",
    "                                    .get_feature_names_out(input_features=categorical_columns)\n",
    "\n",
    "# Convert X_train_preprocessed and X_test_preprocessed to DataFrames\n",
    "\n",
    "X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))\n",
    "X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)',\n",
       "       'pH, water, unfiltered, field, standard units (Maximum)',\n",
       "       'pH, water, unfiltered, field, standard units (Minimum)',\n",
       "       'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)',\n",
       "       'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)',\n",
       "       'Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)',\n",
       "       'Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)',\n",
       "       'Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)',\n",
       "       'Temperature, water, degrees Celsius (Mean)',\n",
       "       'Temperature, water, degrees Celsius (Minimum)',\n",
       "       ...\n",
       "       'Weekday_1', 'Weekday_2', 'Weekday_3', 'Weekday_4', 'Weekday_5',\n",
       "       'Weekday_6', 'Season_Fall', 'Season_Spring', 'Season_Summer',\n",
       "       'Season_Winter'],\n",
       "      dtype='object', length=123)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "Adding hyperparameter tuning.\n",
    "\n",
    "- RMSE based\n",
    "- MAE based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best RMSE: 0.010995486877375305\n",
      "XGBoost RMSE on Validation Data with Best Model: 0.011175057519623414\n",
      "Feature Importance:\n",
      "Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum): 0.4206677973270416\n",
      "Location_ID_21989792.0: 0.11307047307491302\n",
      "Location_ID_2344630.0: 0.01732514798641205\n",
      "Week_48: 0.01672292873263359\n",
      "Location_ID_2336120.0: 0.01628260128200054\n",
      "Week_7: 0.01503604743629694\n",
      "Month_3: 0.013135691173374653\n",
      "Week_27: 0.013066974468529224\n",
      "Location_ID_2203900.0: 0.012845899909734726\n",
      "Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean): 0.012762969359755516\n",
      "Week_24: 0.012113628908991814\n",
      "Location_ID_2203863.0: 0.01208345778286457\n",
      "Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum): 0.01120128482580185\n",
      "Location_ID_2336728.0: 0.010549388825893402\n",
      "pH, water, unfiltered, field, standard units (Minimum): 0.009754205122590065\n",
      "Location_ID_2203831.0: 0.009589968249201775\n",
      "Season_Fall: 0.009460324421525002\n",
      "Location_ID_21989773.0: 0.009154055267572403\n",
      "Month_12: 0.008467252366244793\n",
      "Location_ID_22035975.0: 0.008110049180686474\n",
      "Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum): 0.00796011183410883\n",
      "Month_10: 0.007677190471440554\n",
      "Temperature, water, degrees Celsius (Maximum): 0.006994924508035183\n",
      "Location_ID_2198920.0: 0.006735858041793108\n",
      "Location_ID_2203655.0: 0.006294733379036188\n",
      "Season_Winter: 0.005907912738621235\n",
      "Week_30: 0.005577852949500084\n",
      "Location_ID_2198840.0: 0.005348220467567444\n",
      "Month_2: 0.005327275488525629\n",
      "Location_ID_21989715.0: 0.0052611385472118855\n",
      "Week_2: 0.005147499963641167\n",
      "Temperature, water, degrees Celsius (Minimum): 0.005039696581661701\n",
      "Week_8: 0.004909822251647711\n",
      "Week_12: 0.004806972574442625\n",
      "Location_ID_23362095.0: 0.004702705889940262\n",
      "Temperature, water, degrees Celsius (Mean): 0.0046682581305503845\n",
      "Location_ID_2207160.0: 0.004461342003196478\n",
      "Month_11: 0.004461117088794708\n",
      "Location_ID_2198950.0: 0.004429049789905548\n",
      "Location_ID_219897945.0: 0.004387900698930025\n",
      "Location_ID_2336340.0: 0.004300089552998543\n",
      "Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum): 0.004172592423856258\n",
      "Month_1: 0.0041585080325603485\n",
      "pH, water, unfiltered, field, standard units (Maximum): 0.004061916843056679\n",
      "Location_ID_2203950.0: 0.00383205758407712\n",
      "Dissolved oxygen, water, unfiltered, milligrams per liter (Mean): 0.0038198663387447596\n",
      "Week_11: 0.003806216176599264\n",
      "Location_ID_2336410.0: 0.003781566396355629\n",
      "Location_ID_2336313.0: 0.0033761500380933285\n",
      "Week_5: 0.0033157921861857176\n",
      "Week_41: 0.0031175888143479824\n",
      "Week_14: 0.0028764198068529367\n",
      "Location_ID_2203603.0: 0.0028618830256164074\n",
      "Week_28: 0.002705484628677368\n",
      "Location_ID_2336240.0: 0.0027052448131144047\n",
      "Month_8: 0.002688188338652253\n",
      "Month_7: 0.0026281303726136684\n",
      "Location_ID_2336360.0: 0.002622362691909075\n",
      "Location_ID_2344673.0: 0.002551647601649165\n",
      "Location_ID_2207135.0: 0.0024833527859300375\n",
      "Week_36: 0.0024391694460064173\n",
      "Month_6: 0.0023379281628876925\n",
      "Month_5: 0.0022934291046112776\n",
      "Week_39: 0.002061665989458561\n",
      "Season_Spring: 0.002009495161473751\n",
      "Location_ID_2203960.0: 0.0019859177991747856\n",
      "Location_ID_2337170.0: 0.001983867259696126\n",
      "Location_ID_21989793.0: 0.0019021945772692561\n",
      "Location_ID_2208450.0: 0.001824926701374352\n",
      "Week_33: 0.0017983285943046212\n",
      "Week_23: 0.0017926282016560435\n",
      "Weekday_5: 0.0017912461189553142\n",
      "Week_18: 0.0017227978678420186\n",
      "Location_ID_2208493.0: 0.0017207963392138481\n",
      "Weekday_2: 0.0016712904907763004\n",
      "Week_31: 0.0016691220225766301\n",
      "Week_32: 0.0016534005990251899\n",
      "Month_4: 0.0016529698623344302\n",
      "Location_ID_2203700.0: 0.0016394014237448573\n",
      "Location_ID_2336300.0: 0.0016267686150968075\n",
      "Week_34: 0.0016178912483155727\n",
      "Week_52: 0.0015993892448022962\n",
      "Location_ID_2336152.0: 0.0015563544584438205\n",
      "Week_25: 0.0014627461787313223\n",
      "Week_3: 0.001446455717086792\n",
      "Week_37: 0.0013636576477438211\n",
      "Week_29: 0.001361120375804603\n",
      "Week_9: 0.0012689802097156644\n",
      "Week_10: 0.0012598647736012936\n",
      "Location_ID_2204037.0: 0.0012399695115163922\n",
      "Week_26: 0.0012351528275758028\n",
      "Week_1: 0.0011618273565545678\n",
      "Month_9: 0.0011097962269559503\n",
      "Week_40: 0.0011029444867745042\n",
      "Week_35: 0.0010806565405800939\n",
      "Week_44: 0.0010742682497948408\n",
      "Week_50: 0.0010477511677891016\n",
      "Week_49: 0.0009503576438874006\n",
      "Week_13: 0.0009448419441469014\n",
      "Weekday_3: 0.0009130591643042862\n",
      "Week_15: 0.0009006310137920082\n",
      "Week_17: 0.000828349613584578\n",
      "Location_ID_2336526.0: 0.000774748797994107\n",
      "Week_19: 0.0007123303366824985\n",
      "Week_22: 0.0006874928367324173\n",
      "Week_51: 0.0006837706896476448\n",
      "Week_4: 0.0006678999052383006\n",
      "Week_16: 0.0006086310604587197\n",
      "Weekday_6: 0.000597981212195009\n",
      "Week_38: 0.0005676715518347919\n",
      "Weekday_4: 0.0004974276525899768\n",
      "Week_21: 0.00048319948837161064\n",
      "Weekday_1: 0.00047633523354306817\n",
      "Week_42: 0.00037337015965022147\n",
      "Week_6: 0.0003648886631708592\n",
      "Weekday_0: 0.0003576483577489853\n",
      "Week_47: 0.0003293643821962178\n",
      "Week_20: 0.0002129585773218423\n",
      "Week_46: 0.0001360106107313186\n",
      "Location_ID_2203873.0: 0.0\n",
      "Week_43: 0.0\n",
      "Week_45: 0.0\n",
      "Season_Summer: 0.0\n"
     ]
    }
   ],
   "source": [
    "##### RMSE based\n",
    "\n",
    "# Define XGBoost parameters grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1#, 0.01, 0.001\n",
    "    ],\n",
    "    'n_estimators': [50, 100, 200#, 500\n",
    "    ],\n",
    "    # 'subsample': [0.6, 0.8, 0.9, 1.0],\n",
    "    # 'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    # 'gamma': [0, 0.1, 0.2, 0.5, 1, 1.5, 2, 5],\n",
    "    # 'min_child_weight': [1, 3, 5, 10, 20, 100]\n",
    "}\n",
    "\n",
    "# Create an XGBoost model\n",
    "model_xgb = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "# model_xgb_mae = xgb.XGBRegressor(objective='reg:linear')\n",
    "\n",
    "# Define a custom scoring function (negative RMSE since GridSearchCV minimizes the score)\n",
    "scoring = make_scorer(lambda y_true, y_pred: -mean_squared_error(y_true, y_pred, squared=False))\n",
    "\n",
    "\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "grid_search = GridSearchCV(model_xgb, param_grid, cv=5, scoring=scoring)\n",
    "grid_search.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best model\n",
    "best_xgb_params = grid_search.best_params_\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "best_xgb_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_xgb_params)\n",
    "print(\"Best RMSE:\", -best_xgb_score)\n",
    "\n",
    "# Making predictions on the validation data using the best model\n",
    "y_pred_xgb = best_xgb_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Calculating RMSE on the validation data\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
    "print(\"XGBoost RMSE on Validation Data with Best Model:\", rmse_xgb)\n",
    "# Calculating MAE on the validation data\n",
    "mae_xgb_mae = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(\"XGBoost MAE on Validation Data with Best Model:\", mae_xgb_mae)\n",
    "\n",
    "# Get feature importance scores\n",
    "xgb_feature_importance = best_xgb_model.feature_importances_\n",
    "\n",
    "# Create a list of feature names\n",
    "feature_names = X_train_preprocessed_df.columns\n",
    "\n",
    "# Create a dictionary mapping feature names to their importance scores\n",
    "xgb_feature_importance_dict = dict(zip(feature_names, xgb_feature_importance))\n",
    "\n",
    "# Sort feature importance scores in descending order\n",
    "xgb_sorted_feature_importance = sorted(xgb_feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importance scores\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in xgb_sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "\n",
    "best_xgb_model_info = {'best_params': best_xgb_params, 'best_score': best_xgb_score}\n",
    "\n",
    "# Create a dictionary containing the feature importance results\n",
    "feature_importance_dict = dict(xgb_sorted_feature_importance)\n",
    "\n",
    "# Add the feature importance dictionary to best_xgb_model_info\n",
    "best_xgb_model_info['feature_importance'] = feature_importance_dict\n",
    "best_xgb_model_info['y_pred_xgb'] = y_pred_xgb\n",
    "best_xgb_model_info['y_test'] = y_test\n",
    "best_xgb_model_info['X_test_preprocessed_df'] = X_test_preprocessed_df\n",
    "best_xgb_model_info['y_train'] = y_train\n",
    "best_xgb_model_info['X_train_preprocessed_df'] = X_train_preprocessed_df\n",
    "\n",
    "best_xgb_model_info['rmse_xgb'] = rmse_xgb\n",
    "best_xgb_model_info['mae_xgb_mae'] = mae_xgb_mae\n",
    "\n",
    "best_xgb_file = get_absolute_path(\n",
    "    file_name = 'best_xgb_model.joblib'\n",
    "    , rel_path = 'results'\n",
    ")\n",
    "\n",
    "# Save the updated best_xgb_model_info using save_model function\n",
    "save_model(best_xgb_file, best_xgb_model, best_xgb_model_info)\n",
    "\n",
    "# # Load the model and its info\n",
    "# best_xgb_file = get_absolute_path(\n",
    "#     file_name = 'best_xgb_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "# best_xgb_model, best_xgb_model_info = load_model(best_xgb_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### MAE based\n",
    "\n",
    "\n",
    "# # Create an XGBoost model with 'reg:linear' objective\n",
    "# model_xgb_mae = xgb.XGBRegressor(objective='reg:linear')\n",
    "\n",
    "# # Define a custom scoring function (negative MAE since GridSearchCV minimizes the score)\n",
    "# scoring_mae = make_scorer(lambda y_true, y_pred: -mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "# # Perform hyperparameter tuning using GridSearchCV\n",
    "# grid_search_mae = GridSearchCV(model_xgb_mae, param_grid, cv=5, scoring=scoring_mae)\n",
    "# grid_search_mae.fit(X_train_preprocessed_df, y_train)\n",
    "\n",
    "# # Get the best hyperparameters and best model\n",
    "# best_xgb_params_mae = grid_search_mae.best_params_\n",
    "# best_xgb_model_mae = grid_search_mae.best_estimator_\n",
    "# best_xgb_score_mae = grid_search_mae.best_score_\n",
    "\n",
    "# print(\"Best Hyperparameters (MAE):\", best_xgb_params_mae)\n",
    "# print(\"Best MAE:\", -best_xgb_score_mae)\n",
    "\n",
    "# # Making predictions on the validation data using the best model\n",
    "# y_pred_xgb_mae = best_xgb_model_mae.predict(X_test_preprocessed_df)\n",
    "\n",
    "# # Calculating MAE on the validation data\n",
    "# mae_xgb_mae = mean_absolute_error(y_test, y_pred_xgb_mae)\n",
    "# print(\"XGBoost MAE on Validation Data with Best Model:\", mae_xgb_mae)\n",
    "\n",
    "# # Get feature importance scores\n",
    "# xgb_feature_importance_mae = best_xgb_model_mae.feature_importances_\n",
    "\n",
    "# # Create a list of feature names\n",
    "# feature_names_mae = X_train_preprocessed_df.columns\n",
    "\n",
    "# # Create a dictionary mapping feature names to their importance scores\n",
    "# xgb_feature_importance_dict_mae = dict(zip(feature_names_mae, xgb_feature_importance_mae))\n",
    "\n",
    "# # Sort feature importance scores in descending order\n",
    "# xgb_sorted_feature_importance_mae = sorted(xgb_feature_importance_dict_mae.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Print feature importance scores\n",
    "# print(\"Feature Importance (MAE):\")\n",
    "# for feature, importance in xgb_sorted_feature_importance_mae:\n",
    "#     print(f\"{feature}: {importance}\")\n",
    "\n",
    "# best_xgb_model_info_mae = {'best_params': best_xgb_params_mae, 'best_score': best_xgb_score_mae}\n",
    "\n",
    "# # Create a dictionary containing the feature importance results\n",
    "# feature_importance_dict_mae = dict(xgb_sorted_feature_importance_mae)\n",
    "\n",
    "# # Add the feature importance dictionary to best_xgb_model_info_mae\n",
    "# best_xgb_model_info_mae['feature_importance'] = feature_importance_dict_mae\n",
    "\n",
    "# best_xgb_file_mae = 'best_xgb_model_mae.joblib'\n",
    "\n",
    "# # Save the updated best_xgb_model_info_mae using save_model function\n",
    "# # save_model(best_xgb_file_mae, best_xgb_model_mae, best_xgb_model_info_mae)\n",
    "\n",
    "# # Load the model and its info\n",
    "# # best_xgb_model_mae, best_xgb_model_info_mae = load_model(best_xgb_file_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MAE on Validation Data with Best Model: 0.0064234025687788954\n"
     ]
    }
   ],
   "source": [
    "# Calculating MAE on the validation data\n",
    "mae_xgb_mae = mean_absolute_error(y_test, y_pred_xgb_mae)\n",
    "print(\"XGBoost MAE on Validation Data with Best Model:\", mae_xgb_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "When we don't convert our data to xgb.DMatrix, we can use tools like GridSearchCV directly from scikit-learn. This is because scikit-learn's GridSearchCV works with the standard array-like data formats that scikit-learn supports, such as NumPy arrays and Pandas DataFrames.\n",
    "\n",
    "When we use xgb.DMatrix, we're utilizing XGBoost's own data structure that is optimized for performance, memory usage, and compatibility with XGBoost's specific features. However, this data structure is not natively understood by scikit-learn's utilities like GridSearchCV.\n",
    "\n",
    "If we decide not to convert our data to xgb.DMatrix and we want to use GridSearchCV, we can proceed with our original code. The scikit-learn grid search will work directly with our DataFrame and Series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# # Wrap the XGBoost model in a function\n",
    "# def xgb_predictor(data):\n",
    "#     return best_xgb_model.predict(data)\n",
    "\n",
    "# # Initialize a SHAP explainer with the predictor function\n",
    "# xgb_explainer = shap.Explainer(xgb_predictor, data=dval)\n",
    "\n",
    "# # Calculate SHAP values for a set of data (e.g., dval)\n",
    "# xgb_shap_values = xgb_explainer.shap_values(dval)\n",
    "\n",
    "# # Create a summary plot of feature importances using SHAP\n",
    "# shap.summary_plot(xgb_shap_values, dval, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_xgb_model\n",
    "\n",
    "# _xgb_model = best_xgb_model.fit(dtrain, y_train)\n",
    "\n",
    "# # explain the model's predictions using SHAP\n",
    "# # (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "# _xgb_explainer = shap.Explainer(_xgb_model)\n",
    "# _xgb_shap_values = _xgb_explainer(dtrain)\n",
    "\n",
    "# # visualize the first prediction's explanation\n",
    "# shap.plots.waterfall(_xgb_shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yinpuli/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(model_rf, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m     22\u001b[0m \u001b[39m# grid_search.fit(dtrain, y_train)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train_preprocessed, y_train)\n\u001b[1;32m     26\u001b[0m \u001b[39m# Get the best hyperparameters and best model\u001b[39;00m\n\u001b[1;32m     27\u001b[0m best_rf_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthreads\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39mcurr_sample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/tree/_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(\n\u001b[1;32m   1248\u001b[0m         X,\n\u001b[1;32m   1249\u001b[0m         y,\n\u001b[1;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39mcheck_input,\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py-311/lib/python3.11/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define RandomForest parameters grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100#, 200, 500\n",
    "    ],\n",
    "    'max_depth': [None, 3#, 5, 10, 20\n",
    "    ],\n",
    "    'min_samples_split': [1, 2#, 5, 10\n",
    "    ],\n",
    "    'min_samples_leaf': [1, 2#, 4\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a RandomForest model\n",
    "model_rf = RandomForestRegressor()\n",
    "\n",
    "\n",
    "# Define a custom scoring function (negative RMSE since GridSearchCV minimizes the score)\n",
    "scoring = make_scorer(lambda y_true, y_pred: -mean_squared_error(y_true, y_pred, squared=False))\n",
    "\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "grid_search = GridSearchCV(model_rf, param_grid, cv=5, scoring=scoring)\n",
    "# grid_search.fit(dtrain, y_train)\n",
    "grid_search.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "\n",
    "# Get the best hyperparameters and best model\n",
    "best_rf_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_rf_score = -grid_search.best_score_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_rf_params)\n",
    "print(\"Best RMSE:\", -best_rf_score)\n",
    "\n",
    "# Making predictions on the validation data using the best model\n",
    "y_pred_rf = best_rf_model.predict(X_test_preprocessed_df)\n",
    "\n",
    "# Calculating RMSE on the validation data\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "print(\"RandomForest RMSE on Validation Data with Best Model:\", rmse_rf)\n",
    "# Calculating MAE on the validation data\n",
    "mae_rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(\"RandomForest MAE on Validation Data with Best Model:\", mae_xgb_mae)\n",
    "\n",
    "\n",
    "# Get feature importance scores for the best Random Forest model\n",
    "rf_feature_importance = best_rf_model.feature_importances_\n",
    "\n",
    "# Create a dictionary to map feature names to their importance scores\n",
    "feature_importance_dict = {feature_name: importance_score for feature_name, importance_score in zip(X_train_preprocessed_df.columns, rf_feature_importance)}\n",
    "\n",
    "# Sort feature importance scores in descending order\n",
    "rf_sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importance scores for Random Forest\n",
    "print(\"Random Forest Feature Importance:\")\n",
    "for feature, importance in rf_sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "\n",
    "# Save the best model and results\n",
    "best_rf_model_info = {'best_params': best_rf_params, 'best_score': best_rf_score, 'rmse': rmse_rf}\n",
    "\n",
    "# Add the feature importance dictionary to best_rf_model_info\n",
    "best_rf_model_info['feature_importance'] = feature_importance_dict\n",
    "\n",
    "# Add the feature importance dictionary to best_xgb_model_info\n",
    "\n",
    "best_rf_model_info['y_pred_xgb'] = y_pred_xgb\n",
    "best_rf_model_info['X_test_preprocessed_df'] = X_test_preprocessed_df\n",
    "best_rf_model_info['y_test'] = y_test\n",
    "best_rf_model_info['y_train'] = y_train\n",
    "best_rf_model_info['X_train_preprocessed_df'] = X_train_preprocessed_df\n",
    "best_rf_model_info['rmse_rf'] = rmse_rf\n",
    "best_rf_model_info['mae_rf_mae'] = mae_rf_mae\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_rf_file = get_absolute_path(\n",
    "    file_name='best_rf_model.joblib',\n",
    "    rel_path='results'\n",
    ")\n",
    "save_model(best_rf_file, best_rf_model, best_rf_model_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importance:\n",
      "Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum): 0.8114432607956025\n",
      "Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean): 0.05523080506466742\n",
      "Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum): 0.03645052629807038\n",
      "pH, water, unfiltered, field, standard units (Minimum): 0.024152677368460457\n",
      "Temperature, water, degrees Celsius (Maximum): 0.01893949261600433\n",
      "Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum): 0.011631621147613309\n",
      "pH, water, unfiltered, field, standard units (Maximum): 0.0103268770299261\n",
      "Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum): 0.009883523970297617\n",
      "Temperature, water, degrees Celsius (Mean): 0.008015312669312775\n",
      "Temperature, water, degrees Celsius (Minimum): 0.00788698311428718\n",
      "Dissolved oxygen, water, unfiltered, milligrams per liter (Mean): 0.006038919925758083\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'max_depth': 20,\n",
       "  'min_samples_leaf': 4,\n",
       "  'min_samples_split': 5,\n",
       "  'n_estimators': 100},\n",
       " 'best_score': 0.011567736990528689,\n",
       " 'rmse': 0.01148450307834224,\n",
       " 'feature_importance': {'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)': 0.03645052629807038,\n",
       "  'pH, water, unfiltered, field, standard units (Maximum)': 0.0103268770299261,\n",
       "  'pH, water, unfiltered, field, standard units (Minimum)': 0.024152677368460457,\n",
       "  'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)': 0.011631621147613309,\n",
       "  'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)': 0.05523080506466742,\n",
       "  'Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)': 0.8114432607956025,\n",
       "  'Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)': 0.006038919925758083,\n",
       "  'Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)': 0.009883523970297617,\n",
       "  'Temperature, water, degrees Celsius (Mean)': 0.008015312669312775,\n",
       "  'Temperature, water, degrees Celsius (Minimum)': 0.00788698311428718,\n",
       "  'Temperature, water, degrees Celsius (Maximum)': 0.01893949261600433}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# # Initialize a SHAP explainer\n",
    "# rf_explainer = shap.Explainer(best_rf_model)\n",
    "\n",
    "# # Calculate SHAP values for a set of data (e.g., dval)\n",
    "# rf_shap_values = rf_explainer.shap_values(dval)\n",
    "\n",
    "# # Create a summary plot of feature importances using SHAP\n",
    "# shap.summary_plot(rf_shap_values, dval, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
