{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error,mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from src.shap import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Import data ########\n",
    "\n",
    "\n",
    "y_train = pd.read_csv(get_absolute_path('y_train.csv', 'data'))\n",
    "y_test = pd.read_csv(get_absolute_path('y_test.csv', 'data'))\n",
    "\n",
    "\n",
    "stack_train = pd.read_csv(get_absolute_path('stacked_X_tr.csv', 'data'))\n",
    "stack_test  = pd.read_csv(get_absolute_path('stacked_X_te.csv', 'data'))\n",
    "\n",
    "stack_train = stack_train.astype(column_data_extended_types)\n",
    "stack_test = stack_test.astype(column_data_extended_types)\n",
    "\n",
    "\n",
    "\n",
    "######## Feature Engineering ##########\n",
    "\n",
    "# Select numeric and categorical columns\n",
    "numeric_columns = stack_train.select_dtypes(include=['float64']).columns\n",
    "categorical_columns = [#'Date', \n",
    "                       'Location_ID',\n",
    "                    #    'Year',\n",
    "                       'Month',\n",
    "                       'Week',\n",
    "                       'Weekday',\n",
    "                       'Season'\n",
    "                       ]  # Add any categorical columns here\n",
    "\n",
    "# Create preprocessing transformers\n",
    "numeric_transformer = StandardScaler()  # we can use other scalers as well\n",
    "categorical_transformer = OneHotEncoder(drop=None)  # Use one-hot encoding for categorical columns\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on training data and transform both train and test data\n",
    "X_train_preprocessed = preprocessor.fit_transform(stack_train)\n",
    "X_test_preprocessed  = preprocessor.transform(stack_test)\n",
    "\n",
    "\n",
    "# Get the column names after one-hot encoding\n",
    "categorical_encoded_columns = preprocessor.named_transformers_['cat']\\\n",
    "                                    .get_feature_names_out(input_features=categorical_columns)\n",
    "\n",
    "# Convert X_train_preprocessed and X_test_preprocessed to DataFrames\n",
    "\n",
    "X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))\n",
    "X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_file = get_absolute_path(\n",
    "    file_name = 'best_xgb_model.joblib'\n",
    "    , rel_path = 'results'\n",
    ")\n",
    "\n",
    "best_xgb_shap_file_1 = get_absolute_path(\n",
    "    file_name = 'best_xgb_shap_bar.png'\n",
    "    , rel_path = 'results' + '/' + 'shap'\n",
    ")\n",
    "\n",
    "\n",
    "best_xgb_shap_file_2 = get_absolute_path(\n",
    "    file_name = 'best_xgb_shap_val.png'\n",
    "    , rel_path = 'results' + '/' + 'shap'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_preprocessed_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mshap\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/python-projects/water-quality-prediction/src/shap.py:127\u001b[0m\n\u001b[1;32m    112\u001b[0m best_xgb_shap_file_1 \u001b[39m=\u001b[39m get_absolute_path(\n\u001b[1;32m    113\u001b[0m     file_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbest_xgb_shap_bar.png\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    114\u001b[0m     , rel_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mshap\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    115\u001b[0m )\n\u001b[1;32m    118\u001b[0m best_xgb_shap_file_2 \u001b[39m=\u001b[39m get_absolute_path(\n\u001b[1;32m    119\u001b[0m     file_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbest_xgb_shap_val.png\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m     , rel_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mshap\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    123\u001b[0m gen_shap_results(\n\u001b[1;32m    124\u001b[0m     load_file_path \u001b[39m=\u001b[39m best_xgb_file\n\u001b[1;32m    125\u001b[0m     , save_file_path_1 \u001b[39m=\u001b[39m best_xgb_shap_file_1\n\u001b[1;32m    126\u001b[0m     , save_file_path_2 \u001b[39m=\u001b[39m best_xgb_shap_file_2\n\u001b[0;32m--> 127\u001b[0m     , refit_X \u001b[39m=\u001b[39m X_train_preprocessed_df\n\u001b[1;32m    128\u001b[0m     , refit_y \u001b[39m=\u001b[39m y_train\n\u001b[1;32m    129\u001b[0m     , figure_dpi \u001b[39m=\u001b[39m \u001b[39m300\u001b[39m\n\u001b[1;32m    130\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_preprocessed_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen_shap_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gen_shap_results(\n\u001b[1;32m      2\u001b[0m     load_file_path \u001b[39m=\u001b[39m best_xgb_file\n\u001b[1;32m      3\u001b[0m     , save_file_path_1 \u001b[39m=\u001b[39m best_xgb_shap_file_1\n\u001b[1;32m      4\u001b[0m     , save_file_path_2 \u001b[39m=\u001b[39m best_xgb_shap_file_2\n\u001b[1;32m      5\u001b[0m     , refit_X \u001b[39m=\u001b[39m X_train_preprocessed_df\n\u001b[1;32m      6\u001b[0m     , refit_y \u001b[39m=\u001b[39m y_train\n\u001b[1;32m      7\u001b[0m     , figure_dpi \u001b[39m=\u001b[39m \u001b[39m300\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen_shap_results' is not defined"
     ]
    }
   ],
   "source": [
    "gen_shap_results(\n",
    "    load_file_path = best_xgb_file\n",
    "    , save_file_path_1 = best_xgb_shap_file_1\n",
    "    , save_file_path_2 = best_xgb_shap_file_2\n",
    "    , refit_X = X_train_preprocessed_df\n",
    "    , refit_y = y_train\n",
    "    , figure_dpi = 300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
