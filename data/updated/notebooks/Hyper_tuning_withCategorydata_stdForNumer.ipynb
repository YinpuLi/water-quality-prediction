{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51cb2e5-2516-4205-a366-8e767d062b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1eda89-56b6-45d0-9a29-84bf9a7d9ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('../')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2509357c-3a09-4826-866c-3c417dd3ddd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "# sys.path.append(root_dir)\n",
    "\n",
    "from utils.utils     import *\n",
    "from utils.constants import *\n",
    "from utils.metrics   import *\n",
    "from src.model_tuning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1622ff05-5d37-48ff-ac1a-67076fad4b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_ = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9ae3bd-51d3-413f-a932-9fe44f9f2d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train = pd.read_csv(path_ + '\\\\data' + '\\\\y_train.csv')\n",
    "\n",
    "y_test = pd.read_csv(path_ + '\\\\data' + '\\\\y_test.csv')\n",
    "\n",
    "\n",
    "stack_train = pd.read_csv(path_ + '\\\\data' + '\\\\stacked_X_tr.csv')\n",
    "stack_test  = pd.read_csv(path_ + '\\\\data' + '\\\\stacked_X_te.csv')\n",
    "\n",
    "\n",
    "# y_train = pd.read_csv(get_absolute_path('y_train.csv', 'data'))\n",
    "# y_test = pd.read_csv(get_absolute_path('y_test.csv', 'data'))\n",
    "\n",
    "\n",
    "# stack_train = pd.read_csv(get_absolute_path('stacked_X_tr.csv', 'data'))\n",
    "# stack_test  = pd.read_csv(get_absolute_path('stacked_X_te.csv', 'data'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc226add-8520-47f1-a703-a5371ff208c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "stack_train = stack_train.astype(column_data_extended_types)\n",
    "stack_test = stack_test.astype(column_data_extended_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90850d30-a299-4110-b772-22eac79fe0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######## Feature Engineering ##########\n",
    "\n",
    "# Select numeric and categorical columns\n",
    "numeric_columns = stack_train.select_dtypes(include=['float64']).columns\n",
    "categorical_columns = [#'Date', \n",
    "                       'Location_ID',\n",
    "                    #    'Year',\n",
    "                       'Month',\n",
    "                       'Week',\n",
    "                       'Weekday',\n",
    "                       'Season'\n",
    "                       ]  # Add any categorical columns here\n",
    "\n",
    "# Create preprocessing transformers\n",
    "numeric_transformer = StandardScaler()  # we can use other scalers as well\n",
    "categorical_transformer = OneHotEncoder(drop=None)  # Use one-hot encoding for categorical columns\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on training data and transform both train and test data\n",
    "X_train_preprocessed = preprocessor.fit_transform(stack_train)\n",
    "X_test_preprocessed  = preprocessor.transform(stack_test)\n",
    "\n",
    "\n",
    "# Get the column names after one-hot encoding\n",
    "categorical_encoded_columns = preprocessor.named_transformers_['cat']\\\n",
    "                                    .get_feature_names_out(input_features=categorical_columns)\n",
    "\n",
    "# Convert X_train_preprocessed and X_test_preprocessed to DataFrames\n",
    "\n",
    "X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))\n",
    "X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))\n",
    "\n",
    "scoring=make_scorer(lambda y_true, y_pred: -mean_squared_error(y_true, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3290a324-42ed-479c-82f6-61e69da25643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_preprocessed_df.to_csv('aaa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a66f44-f22d-4d43-81b1-1073d121c598",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3704928-f03e-4f5c-bd0d-0ff7a39c5827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n",
      "best_params: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 20, 'n_estimators': 500, 'random_state': 827, 'subsample': 0.8}\n",
      "1\n",
      "eval_metrics: {'rmse': 0.011139175966361239, 'mape': 0.009287988656448153, 'wmape': 0.009435331851106944, 'wbias': 0.0011219685420847771, 'wuforec': 0.00527865019659586, 'woforec': 0.004156681654511083}\n",
      "Success of xgboost!\n"
     ]
    }
   ],
   "source": [
    "######### XGBoost #########\n",
    "\n",
    "# best_xgb_file = get_absolute_path(\n",
    "#     file_name = 'best_xgb_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_xgb_file =  path_ + '\\\\results' + '\\\\best_xgb_model.joblib'\n",
    "\n",
    "\n",
    "xgb_result = hyperparameter_tuning(\n",
    "        X_train=X_train_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid={\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.1, 0.01],\n",
    "            'n_estimators': [100, 200, 500, 800],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'gamma': [0, 0.1, 0.5],\n",
    "            'min_child_weight': [1, 5, 10, 20],\n",
    "            'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_SEED),\n",
    "        scoring=scoring,\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_xgb_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "\n",
    "print(\"Success of xgboost!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80aa26f1-da32-4aee-b0d4-08a38bfbc9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\xgb_result.json\"), \"w\") as outfile:\n",
    "    json.dump(str(xgb_result), outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64dd8b3b-2e7d-453d-ad57-e9a2d626953a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "300 fits failed out of a total of 1200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"D:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"D:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan -0.01201927 -0.01190558\n",
      " -0.01182949 -0.01181015 -0.01197419 -0.01187922 -0.01183682 -0.01181672\n",
      " -0.01200808 -0.01191087 -0.01183923 -0.01183418         nan         nan\n",
      "         nan         nan -0.01185314 -0.01174572 -0.01170504 -0.0117074\n",
      " -0.01185441 -0.01174637 -0.01171605 -0.01170808 -0.01186382 -0.01177185\n",
      " -0.01176442 -0.01173489         nan         nan         nan         nan\n",
      " -0.01160483 -0.01156968 -0.01155109 -0.01154369 -0.01160483 -0.01156968\n",
      " -0.01155109 -0.01154369 -0.01159385 -0.01156349 -0.01154553 -0.01154055\n",
      "         nan         nan         nan         nan -0.01502037 -0.01502576\n",
      " -0.01501266 -0.01501765 -0.01502037 -0.01502576 -0.01501266 -0.01501765\n",
      " -0.01502037 -0.01502576 -0.01501266 -0.01501765         nan         nan\n",
      "         nan         nan -0.01502037 -0.01502576 -0.01501266 -0.01501765\n",
      " -0.01502037 -0.01502576 -0.01501266 -0.01501765 -0.01502037 -0.01502576\n",
      " -0.01501266 -0.01501765         nan         nan         nan         nan\n",
      " -0.01502037 -0.01502576 -0.01501266 -0.01501765 -0.01502037 -0.01502576\n",
      " -0.01501266 -0.01501765 -0.01502037 -0.01502576 -0.01501266 -0.01501765\n",
      "         nan         nan         nan         nan -0.01307294 -0.01307154\n",
      " -0.01304987 -0.01306464 -0.01307295 -0.01307168 -0.01304903 -0.01306464\n",
      " -0.01307758 -0.01307774 -0.01305222 -0.01306701         nan         nan\n",
      "         nan         nan -0.01302272 -0.01303138 -0.01301524 -0.01301316\n",
      " -0.0130233  -0.0130321  -0.01301546 -0.0130141  -0.01302759 -0.01303802\n",
      " -0.01301866 -0.01301679         nan         nan         nan         nan\n",
      " -0.01290081 -0.01292746 -0.01290842 -0.01290597 -0.01290081 -0.01292746\n",
      " -0.01290842 -0.01290597 -0.01290087 -0.0129278  -0.01290897 -0.01290657\n",
      "         nan         nan         nan         nan -0.01230234 -0.0121997\n",
      " -0.01214337 -0.01212147 -0.01229061 -0.01218025 -0.01213322 -0.0121233\n",
      " -0.01223869 -0.01215071 -0.01213092 -0.012144           nan         nan\n",
      "         nan         nan -0.0121346  -0.01204527 -0.01201995 -0.01201341\n",
      " -0.01214484 -0.01205079 -0.01201397 -0.01200702 -0.0121439  -0.01206877\n",
      " -0.0120453  -0.01203254         nan         nan         nan         nan\n",
      " -0.01185429 -0.0118346  -0.01180794 -0.01180155 -0.01185429 -0.0118346\n",
      " -0.01180794 -0.01180155 -0.01185712 -0.01183089 -0.01180518 -0.011801\n",
      "         nan         nan         nan         nan -0.01197301 -0.01186872\n",
      " -0.01181402 -0.01182489 -0.01202942 -0.01190524 -0.01183318 -0.01183035\n",
      " -0.01200296 -0.01188994 -0.01184601 -0.01184911         nan         nan\n",
      "         nan         nan -0.01189595 -0.01175148 -0.01171921 -0.01170542\n",
      " -0.011884   -0.01177466 -0.01174377 -0.01172157 -0.01187699 -0.01178397\n",
      " -0.01175835 -0.01174683         nan         nan         nan         nan\n",
      " -0.01161301 -0.01157038 -0.01155011 -0.01154662 -0.01161301 -0.01157038\n",
      " -0.01155011 -0.01154662 -0.01159729 -0.01156659 -0.0115457  -0.01154682]\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 500, 'random_state': 827}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "eval_metrics: {'rmse': 0.011711301749508506, 'mape': 0.009704659203291449, 'wmape': 0.009874166809129547, 'wbias': 0.0006525708211954504, 'wuforec': 0.005263368815162498, 'woforec': 0.004610797993967048}\n",
      "Success of rf!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######### Random Forest #########\n",
    "\n",
    "# best_rf_file = get_absolute_path(\n",
    "#     file_name = 'best_rf_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_rf_file =  path_ + '\\\\results' + '\\\\best_rf_model.joblib'\n",
    "\n",
    "\n",
    "rf_result = hyperparameter_tuning(\n",
    "        X_train=X_train_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid={\n",
    "           'n_estimators': [50, 100, 200, 500],\n",
    "           'max_depth': [None, 3, 5, 10, 20],\n",
    "           'min_samples_split': [1, 2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=RandomForestRegressor(random_state=RANDOM_SEED),\n",
    "        scoring=scoring,\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_rf_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "print(\"Success of rf!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32dcee4f-9796-49c8-99c3-53c930f88f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\rf_result.json\"), \"w\") as outfile:\n",
    "    json.dump(str(rf_result), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cea72de-1dd9-46ef-a542-9ccc9384345a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'activation': 'tanh', 'hidden_layer_sizes': (2000, 500), 'random_state': 827}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "eval_metrics: {'rmse': 0.014420387318514635, 'mape': 0.014541122244407076, 'wmape': 0.014607689864116317, 'wbias': 0.003969996490200376, 'wuforec': 0.009288843177158347, 'woforec': 0.005318846686957972}\n",
      "Success of MLP!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "######### MLP #########\n",
    "\n",
    "# best_mlp_file = get_absolute_path(\n",
    "#     file_name = 'best_mlp_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_mlp_file =  path_ + '\\\\results' + '\\\\best_mlp_model.joblib'\n",
    "\n",
    "\n",
    "\n",
    "mlp_result = hyperparameter_tuning(\n",
    "        X_train=X_test_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid= {\n",
    "            'hidden_layer_sizes': list(zip([1000,2000, 3000, 5000], [300, 500, 800, 1000])),\n",
    "            #'max_iter': [50, 100],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            #'solver': ['sgd', 'adam'],\n",
    "            #'alpha': [0.0001, 0.05],\n",
    "            #'learning_rate': ['constant','adaptive'],\n",
    "            'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=MLPRegressor(random_state=RANDOM_SEED),\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_mlp_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "print(\"Success of MLP!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf705505-00c7-4d85-803e-58f7beb5b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\mlp_result.json\"), \"w\") as outfile:\n",
    "    json.dump(str(mlp_result), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0afaec73-7277-4016-a55e-69d4548936c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.456e-02, tolerance: 1.345e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'alpha': 1e-05, 'l1_ratio': 1, 'random_state': 827}\n",
      "1\n",
      "eval_metrics: {'rmse': 0.011913692392905538, 'mape': 0.010792014828810443, 'wmape': 0.010957849504397259, 'wbias': 0.0013146181043679776, 'wuforec': 0.006136233804382618, 'woforec': 0.0048216157000146405}\n",
      "Success of ElasticNet!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.456e-02, tolerance: 1.345e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######### ElasticNet #########\n",
    "\n",
    "# best_lin_file = get_absolute_path(\n",
    "#     file_name = 'best_lin_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_lin_file =  path_ + '\\\\results' + '\\\\best_lin_model.joblib'\n",
    "\n",
    "\n",
    "lin_result = hyperparameter_tuning(\n",
    "        X_train=X_train_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid={\n",
    "            \"alpha\":[0.01, 0.001, 0.0001, 0.00001, 0.000001],\n",
    "            \"l1_ratio\": [0, 0.1, 0.3, 0.5, 0.8, 1],\n",
    "            'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=ElasticNet(random_state=RANDOM_SEED).fit(X_train_preprocessed_df,y_train),\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_lin_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "print(\"Success of ElasticNet!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a47c346b-0e10-4b47-abea-91b78150f58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\lin_result.json\"), \"w\") as outfile:\n",
    "    json.dump(str(lin_result), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0eae5-89fc-478d-bc00-aee755650075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "097e4eaa-f783-4e47-ae0a-ab48f5a3ef6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "best_params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 800, 'num_leaves': 20, 'random_state': 827}\n",
      "1\n",
      "eval_metrics: {'rmse': 0.011040168862164742, 'mape': 0.009217976090447567, 'wmape': 0.009357888399115846, 'wbias': 0.0009469266898897603, 'wuforec': 0.005152407544502803, 'woforec': 0.004205480854613044}\n",
      "Success of LightGBM!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######### lightGBM #########\n",
    "\n",
    "## rename the features for an feature name error (only for lightGBM).\n",
    "import re\n",
    "X_train_preprocessed_df = X_train_preprocessed_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "X_test_preprocessed_df = X_test_preprocessed_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "\n",
    "# best_best_lightGBM_file = get_absolute_path(\n",
    "#     file_name = 'best_lightGBM_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_lightGBM_file =  path_ + '\\\\results' + '\\\\best_lightGBM_model.joblib'\n",
    "\n",
    "\n",
    "lightGBM_result = hyperparameter_tuning(\n",
    "        X_train=X_train_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid={\n",
    "                'max_depth': [3, 5, 7, 15],\n",
    "                'learning_rate': [0.5, 0.1, 0.01, 0.001],\n",
    "                'num_leaves': [20, 31, 50, 100,200],\n",
    "                'n_estimators': [50, 100, 200, 500, 800],\n",
    "                'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=lgb.LGBMRegressor(objective='regression', metric='rmse', random_state=RANDOM_SEED).fit(X_train_preprocessed_df,y_train),\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_lightGBM_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "print(\"Success of LightGBM!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e240cbb-4da3-442a-b128-7a009427a280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\lightGBM_model.json\"), \"w\") as outfile:\n",
    "    json.dump(str(lightGBM_result), outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
