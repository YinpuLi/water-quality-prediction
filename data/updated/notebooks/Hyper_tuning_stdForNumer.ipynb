{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51cb2e5-2516-4205-a366-8e767d062b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1eda89-56b6-45d0-9a29-84bf9a7d9ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('../')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2509357c-3a09-4826-866c-3c417dd3ddd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "# sys.path.append(root_dir)\n",
    "\n",
    "from utils.utils     import *\n",
    "from utils.constants import *\n",
    "from utils.metrics   import *\n",
    "from src.model_tuning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1622ff05-5d37-48ff-ac1a-67076fad4b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_ = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9ae3bd-51d3-413f-a932-9fe44f9f2d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train = pd.read_csv(path_ + '\\\\data' + '\\\\y_train.csv')\n",
    "\n",
    "y_test = pd.read_csv(path_ + '\\\\data' + '\\\\y_test.csv')\n",
    "\n",
    "\n",
    "stack_train = pd.read_csv(path_ + '\\\\data' + '\\\\stacked_X_tr.csv')\n",
    "stack_test  = pd.read_csv(path_ + '\\\\data' + '\\\\stacked_X_te.csv')\n",
    "\n",
    "\n",
    "# y_train = pd.read_csv(get_absolute_path('y_train.csv', 'data'))\n",
    "# y_test = pd.read_csv(get_absolute_path('y_test.csv', 'data'))\n",
    "\n",
    "\n",
    "# stack_train = pd.read_csv(get_absolute_path('stacked_X_tr.csv', 'data'))\n",
    "# stack_test  = pd.read_csv(get_absolute_path('stacked_X_te.csv', 'data'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc226add-8520-47f1-a703-a5371ff208c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "stack_train = stack_train.astype(column_data_extended_types)\n",
    "stack_test = stack_test.astype(column_data_extended_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90850d30-a299-4110-b772-22eac79fe0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######## Feature Engineering ##########\n",
    "\n",
    "# Select numeric and categorical columns\n",
    "numeric_columns = stack_train.select_dtypes(include=['float64']).columns\n",
    "categorical_columns = [#'Date', \n",
    "                       'Location_ID',\n",
    "                    #    'Year',\n",
    "                       'Month',\n",
    "                       'Week',\n",
    "                       'Weekday',\n",
    "                       'Season'\n",
    "                       ]  # Add any categorical columns here\n",
    "\n",
    "# Create preprocessing transformers\n",
    "numeric_transformer = StandardScaler()  # we can use other scalers as well\n",
    "categorical_transformer = OneHotEncoder(drop=None)  # Use one-hot encoding for categorical columns\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on training data and transform both train and test data\n",
    "X_train_preprocessed = preprocessor.fit_transform(stack_train)\n",
    "X_test_preprocessed  = preprocessor.transform(stack_test)\n",
    "\n",
    "\n",
    "# Get the column names after one-hot encoding\n",
    "categorical_encoded_columns = preprocessor.named_transformers_['cat']\\\n",
    "                                    .get_feature_names_out(input_features=categorical_columns)\n",
    "\n",
    "# Convert X_train_preprocessed and X_test_preprocessed to DataFrames\n",
    "\n",
    "X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))\n",
    "X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))\n",
    "\n",
    "scoring=make_scorer(lambda y_true, y_pred: -mean_squared_error(y_true, y_pred, squared=False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_preprocessed_df = X_train_preprocessed_df[column_names_raw]\n",
    "X_test_preprocessed_df = X_test_preprocessed_df[column_names_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a66f44-f22d-4d43-81b1-1073d121c598",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3704928-f03e-4f5c-bd0d-0ff7a39c5827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n",
      "best_params: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 20, 'n_estimators': 800, 'random_state': 827, 'subsample': 0.8}\n",
      "eval_metrics: {'rmse': 0.010957830248512337, 'mape': 0.009221277715411659, 'wmape': 0.009363284939395644, 'wbias': 0.0009845337036232251, 'wuforec': 0.005173909321509434, 'woforec': 0.00418937561788621}\n",
      "Success of xgboost!\n"
     ]
    }
   ],
   "source": [
    "######### XGBoost #########\n",
    "\n",
    "# best_xgb_file = get_absolute_path(\n",
    "#     file_name = 'best_xgb_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_xgb_file =  path_ + '\\\\results' + '\\\\best_xgb_model.joblib'\n",
    "\n",
    "\n",
    "xgb_result = hyperparameter_tuning(\n",
    "        X_train=X_train_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid={\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.1, 0.01],\n",
    "            'n_estimators': [100, 200, 500, 800],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'gamma': [0, 0.1, 0.5],\n",
    "            'min_child_weight': [1, 5, 10, 20],\n",
    "            'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_SEED),\n",
    "        scoring=scoring,\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_xgb_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "\n",
    "print(\"Success of xgboost!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80aa26f1-da32-4aee-b0d4-08a38bfbc9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\xgb_result.json\"), \"w\") as outfile:\n",
    "    json.dump(str(xgb_result), outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64dd8b3b-2e7d-453d-ad57-e9a2d626953a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "300 fits failed out of a total of 1200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"D:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"D:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan -0.01215786 -0.0120036\n",
      " -0.01195118 -0.0119188  -0.01208759 -0.01195955 -0.01191524 -0.011882\n",
      " -0.01202792 -0.01192826 -0.01189444 -0.01187662         nan         nan\n",
      "         nan         nan -0.01193452 -0.01180045 -0.01174943 -0.01170371\n",
      " -0.01192316 -0.01181573 -0.01174965 -0.01169537 -0.01189087 -0.01179434\n",
      " -0.01175397 -0.01170744         nan         nan         nan         nan\n",
      " -0.0117292  -0.01167339 -0.01164096 -0.01160064 -0.0117292  -0.01167339\n",
      " -0.01164096 -0.01160064 -0.01171931 -0.01166979 -0.01164037 -0.01159809\n",
      "         nan         nan         nan         nan -0.0148467  -0.01485333\n",
      " -0.01484028 -0.01484199 -0.0148467  -0.01485333 -0.01484028 -0.01484199\n",
      " -0.0148467  -0.01485333 -0.01484028 -0.01484199         nan         nan\n",
      "         nan         nan -0.0148467  -0.01485333 -0.01484028 -0.01484199\n",
      " -0.0148467  -0.01485333 -0.01484028 -0.01484199 -0.0148467  -0.01485333\n",
      " -0.01484028 -0.01484199         nan         nan         nan         nan\n",
      " -0.0148467  -0.01485333 -0.01484028 -0.01484199 -0.0148467  -0.01485333\n",
      " -0.01484028 -0.01484199 -0.0148467  -0.01485333 -0.01484028 -0.01484199\n",
      "         nan         nan         nan         nan -0.01302343 -0.01300722\n",
      " -0.01298437 -0.01298968 -0.01302225 -0.01300658 -0.01298458 -0.0129905\n",
      " -0.01302735 -0.01301182 -0.01298574 -0.01299284         nan         nan\n",
      "         nan         nan -0.01294628 -0.01294683 -0.01291882 -0.01290537\n",
      " -0.01294509 -0.01294615 -0.01291856 -0.0129051  -0.01295015 -0.01294984\n",
      " -0.01291964 -0.01290762         nan         nan         nan         nan\n",
      " -0.01292471 -0.01292102 -0.01289449 -0.01287833 -0.01292471 -0.01292102\n",
      " -0.01289449 -0.01287833 -0.01292528 -0.01292158 -0.01289456 -0.01287878\n",
      "         nan         nan         nan         nan -0.01233876 -0.01219993\n",
      " -0.0121624  -0.01211488 -0.0122216  -0.01212931 -0.01211714 -0.01209265\n",
      " -0.01225333 -0.01216011 -0.01212434 -0.01209689         nan         nan\n",
      "         nan         nan -0.012128   -0.01201036 -0.01197383 -0.01192514\n",
      " -0.01213466 -0.0120386  -0.01197232 -0.01192164 -0.01204897 -0.01199133\n",
      " -0.01196133 -0.01192943         nan         nan         nan         nan\n",
      " -0.01192327 -0.01187622 -0.01184314 -0.01180623 -0.01192327 -0.01187622\n",
      " -0.01184314 -0.01180623 -0.01189871 -0.01186522 -0.01184191 -0.01180037\n",
      "         nan         nan         nan         nan -0.01217551 -0.01199761\n",
      " -0.01192398 -0.0118832  -0.01208389 -0.01193046 -0.01190178 -0.01187533\n",
      " -0.01202556 -0.0119326  -0.01187803 -0.01186516         nan         nan\n",
      "         nan         nan -0.01195135 -0.01182903 -0.01177786 -0.01171263\n",
      " -0.01191222 -0.01180088 -0.01176044 -0.01170801 -0.01189916 -0.01182308\n",
      " -0.0117647  -0.01172194         nan         nan         nan         nan\n",
      " -0.01171456 -0.01166867 -0.01163815 -0.01159959 -0.01171456 -0.01166867\n",
      " -0.01163815 -0.01159959 -0.01170066 -0.01165723 -0.01162987 -0.01159297]\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 500, 'random_state': 827}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_metrics: {'rmse': 0.011471895705663855, 'mape': 0.009710125117257443, 'wmape': 0.009865323382071042, 'wbias': 0.0008373675309925635, 'wuforec': 0.005351345456531802, 'woforec': 0.004513977925539239}\n",
      "Success of rf!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######### Random Forest #########\n",
    "\n",
    "# best_rf_file = get_absolute_path(\n",
    "#     file_name = 'best_rf_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_rf_file =  path_ + '\\\\results' + '\\\\best_rf_model.joblib'\n",
    "\n",
    "\n",
    "rf_result = hyperparameter_tuning(\n",
    "        X_train=X_train_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid={\n",
    "           'n_estimators': [50, 100, 200, 500],\n",
    "           'max_depth': [None, 3, 5, 10, 20],\n",
    "           'min_samples_split': [1, 2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=RandomForestRegressor(random_state=RANDOM_SEED),\n",
    "        scoring=scoring,\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_rf_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "print(\"Success of rf!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32dcee4f-9796-49c8-99c3-53c930f88f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\rf_result.json\"), \"w\") as outfile:\n",
    "    json.dump(str(rf_result), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cea72de-1dd9-46ef-a542-9ccc9384345a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'activation': 'relu', 'hidden_layer_sizes': (3000, 800), 'random_state': 827}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_metrics: {'rmse': 0.01419767849167211, 'mape': 0.012918802192416545, 'wmape': 0.013160718432543647, 'wbias': -0.005498877971762316, 'wuforec': 0.003830920230390667, 'woforec': 0.009329798202152982}\n",
      "Success of MLP!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "######### MLP #########\n",
    "\n",
    "# best_mlp_file = get_absolute_path(\n",
    "#     file_name = 'best_mlp_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_mlp_file =  path_ + '\\\\results' + '\\\\best_mlp_model.joblib'\n",
    "\n",
    "\n",
    "\n",
    "mlp_result = hyperparameter_tuning(\n",
    "        X_train=X_train_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid= {\n",
    "            'hidden_layer_sizes': list(zip([1000,2000, 3000, 5000], [300, 500, 800, 1000])),\n",
    "            #'max_iter': [50, 100],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            #'solver': ['sgd', 'adam'],\n",
    "            #'alpha': [0.0001, 0.05],\n",
    "            #'learning_rate': ['constant','adaptive'],\n",
    "            'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=MLPRegressor(random_state=RANDOM_SEED),\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_mlp_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "print(\"Success of MLP!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf705505-00c7-4d85-803e-58f7beb5b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\mlp_result.json\"), \"w\") as outfile:\n",
    "    json.dump(str(mlp_result), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0afaec73-7277-4016-a55e-69d4548936c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "best_params: {'alpha': 1e-06, 'l1_ratio': 0, 'random_state': 827}\n",
      "eval_metrics: {'rmse': 0.012036930325712495, 'mape': 0.010742294902159272, 'wmape': 0.010915650002954672, 'wbias': 0.00040647847810628844, 'wuforec': 0.0056610642405304805, 'woforec': 0.0052545857624241915}\n",
      "Success of ElasticNet!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+00, tolerance: 1.345e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+00, tolerance: 1.345e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######### ElasticNet #########\n",
    "\n",
    "# best_lin_file = get_absolute_path(\n",
    "#     file_name = 'best_lin_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_lin_file =  path_ + '\\\\results' + '\\\\best_lin_model.joblib'\n",
    "\n",
    "\n",
    "lin_result = hyperparameter_tuning(\n",
    "        X_train=X_train_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid={\n",
    "            \"alpha\":[0.01, 0.001, 0.0001, 0.00001, 0.000001],\n",
    "            \"l1_ratio\": [0, 0.1, 0.3, 0.5, 0.8, 1],\n",
    "            'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=ElasticNet(random_state=RANDOM_SEED).fit(X_train_preprocessed_df,y_train),\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_lin_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "print(\"Success of ElasticNet!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a47c346b-0e10-4b47-abea-91b78150f58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\lin_result.json\"), \"w\") as outfile:\n",
    "    json.dump(str(lin_result), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0eae5-89fc-478d-bc00-aee755650075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "097e4eaa-f783-4e47-ae0a-ab48f5a3ef6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "best_params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'num_leaves': 20, 'random_state': 827}\n",
      "eval_metrics: {'rmse': 0.010843662111841292, 'mape': 0.009327065730018333, 'wmape': 0.009465059255443473, 'wbias': 0.0008620482732707277, 'wuforec': 0.005163553764357101, 'woforec': 0.004301505491086373}\n",
      "Success of LightGBM!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######### lightGBM #########\n",
    "\n",
    "## rename the features for an feature name error (only for lightGBM).\n",
    "import re\n",
    "X_train_preprocessed_df = X_train_preprocessed_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "X_test_preprocessed_df = X_test_preprocessed_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "\n",
    "# best_best_lightGBM_file = get_absolute_path(\n",
    "#     file_name = 'best_lightGBM_model.joblib'\n",
    "#     , rel_path = 'results'\n",
    "# )\n",
    "\n",
    "best_lightGBM_file =  path_ + '\\\\results' + '\\\\best_lightGBM_model.joblib'\n",
    "\n",
    "\n",
    "lightGBM_result = hyperparameter_tuning(\n",
    "        X_train=X_train_preprocessed_df,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_preprocessed_df,\n",
    "        y_test=y_test,\n",
    "        param_grid={\n",
    "                'max_depth': [3, 5, 7, 15],\n",
    "                'learning_rate': [0.5, 0.1, 0.01, 0.001],\n",
    "                'num_leaves': [20, 31, 50, 100,200],\n",
    "                'n_estimators': [50, 100, 200, 500, 800],\n",
    "                'random_state': [RANDOM_SEED]\n",
    "        },\n",
    "        model=lgb.LGBMRegressor(objective='regression', metric='rmse', random_state=RANDOM_SEED).fit(X_train_preprocessed_df,y_train),\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        eval_func=compute_metrics,\n",
    "        file_path=best_lightGBM_file,\n",
    "        cv=5\n",
    ") \n",
    "\n",
    "print(\"Success of LightGBM!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e240cbb-4da3-442a-b128-7a009427a280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open((path_ + '\\\\results' + \"\\\\lightGBM_model.json\"), \"w\") as outfile:\n",
    "    json.dump(str(lightGBM_result), outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
