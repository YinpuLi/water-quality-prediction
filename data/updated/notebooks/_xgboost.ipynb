{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error,mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "\n",
    "y_train = pd.read_csv(get_absolute_path('y_train.csv', 'data'))\n",
    "y_test  = pd.read_csv(get_absolute_path('y_test.csv', 'data'))\n",
    "\n",
    "\n",
    "stack_train = pd.read_csv(get_absolute_path('stacked_X_tr.csv', 'data'))\n",
    "stack_test  = pd.read_csv(get_absolute_path('stacked_X_te.csv', 'data'))\n",
    "\n",
    "stack_train = stack_train.astype(column_data_extended_types)\n",
    "stack_test = stack_test.astype(column_data_extended_types)\n",
    "\n",
    "# Select numeric and categorical columns\n",
    "numeric_columns = stack_train.select_dtypes(include=['float64']).columns\n",
    "categorical_columns = [#'Date', \n",
    "                       'Location_ID',\n",
    "                    #    'Year',\n",
    "                       'Month',\n",
    "                       'Week',\n",
    "                       'Weekday',\n",
    "                       'Season'\n",
    "                       ]  # Add any categorical columns here\n",
    "\n",
    "# Create preprocessing transformers\n",
    "numeric_transformer = StandardScaler()  # we can use other scalers as well\n",
    "categorical_transformer = OneHotEncoder(drop=None)  # Use one-hot encoding for categorical columns\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on training data and transform both train and test data\n",
    "X_train_preprocessed = preprocessor.fit_transform(stack_train)\n",
    "X_test_preprocessed  = preprocessor.transform(stack_test)\n",
    "\n",
    "\n",
    "# Get the column names after one-hot encoding\n",
    "categorical_encoded_columns = preprocessor.named_transformers_['cat']\\\n",
    "                                    .get_feature_names_out(input_features=categorical_columns)\n",
    "\n",
    "# Convert X_train_preprocessed and X_test_preprocessed to DataFrames\n",
    "\n",
    "X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))\n",
    "X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed.toarray(), columns=np.concatenate([numeric_columns, categorical_encoded_columns]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_tuning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_file = get_absolute_path(\n",
    "file_name = 'best_xgb_model.joblib'\n",
    ", rel_path = 'results'\n",
    ")\n",
    "\n",
    "scoring=make_scorer(lambda y_true, y_pred: -mean_squared_error(y_true, y_pred, squared=False))\n",
    "\n",
    "X_train=X_train_preprocessed_df\n",
    "y_train=y_train\n",
    "X_test=X_test_preprocessed_df\n",
    "y_test=y_test\n",
    "param_grid={\n",
    "    'max_depth': [3]#, 5, 7],\n",
    "    # 'learning_rate': [0.1, 0.01],\n",
    "    # 'n_estimators': [100, 200, 500],\n",
    "    # 'subsample': [0.8, 1.0],\n",
    "    # 'colsample_bytree': [0.8, 1.0],\n",
    "    # 'gamma': [0, 0.1, 0.5],\n",
    "    # 'min_child_weight': [1, 5, 10, 20]\n",
    "}\n",
    "model=xgb.XGBRegressor(objective='reg:squarederror')\n",
    "scoring=scoring\n",
    "eval_func=compute_metrics\n",
    "file_path=best_xgb_file\n",
    "cv=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "grid_search = GridSearchCV(model, param_grid, cv=cv, scoring=scoring, n_jobs=6, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Making predictions on the validation data using the best model\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the validation data using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "_df = pd.DataFrame(\n",
    "    {\n",
    "        'forecast': y_pred,\n",
    "        'actual': y_test['measurement']\n",
    "    }\n",
    ")\n",
    "eval_metrics = eval_func(_df, EVAL_METRIC_LIST)\n",
    "\n",
    "# Get feature importance scores for tree based models\n",
    "\n",
    "if isinstance(best_model, MLPRegressor): # type(best_model) == MLPRegressor\n",
    "    feature_importance_dict = {}\n",
    "else:\n",
    "    # Get feature importance scores\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "    feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "\n",
    "# Save the results\n",
    "best_model_info = {\n",
    "    'best_params': best_params,\n",
    "    'best_score': best_score,\n",
    "    'feature_importance': feature_importance_dict,\n",
    "    'eval_metrics': eval_metrics\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'max_depth': 3},\n",
       " 'best_score': -0.010876995817059615,\n",
       " 'feature_importance': {'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)': 0.01882037,\n",
       "  'pH, water, unfiltered, field, standard units (Maximum)': 0.0058287554,\n",
       "  'pH, water, unfiltered, field, standard units (Minimum)': 0.0051923725,\n",
       "  'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)': 0.0035735324,\n",
       "  'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)': 0.018743103,\n",
       "  'Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)': 0.46717146,\n",
       "  'Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)': 0.002534969,\n",
       "  'Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)': 0.012307011,\n",
       "  'Temperature, water, degrees Celsius (Mean)': 0.0040799812,\n",
       "  'Temperature, water, degrees Celsius (Minimum)': 0.010898472,\n",
       "  'Temperature, water, degrees Celsius (Maximum)': 0.013142952,\n",
       "  'Location_ID_2198840.0': 0.0041760365,\n",
       "  'Location_ID_2198920.0': 0.012411853,\n",
       "  'Location_ID_2198950.0': 0.0039383247,\n",
       "  'Location_ID_21989715.0': 0.0039640283,\n",
       "  'Location_ID_21989773.0': 0.009663878,\n",
       "  'Location_ID_21989792.0': 0.115883835,\n",
       "  'Location_ID_21989793.0': 0.0008970732,\n",
       "  'Location_ID_219897945.0': 0.0,\n",
       "  'Location_ID_22035975.0': 0.0,\n",
       "  'Location_ID_2203603.0': 0.0021004989,\n",
       "  'Location_ID_2203655.0': 0.0,\n",
       "  'Location_ID_2203700.0': 0.0,\n",
       "  'Location_ID_2203831.0': 0.004566345,\n",
       "  'Location_ID_2203863.0': 0.011429324,\n",
       "  'Location_ID_2203873.0': 0.0009303511,\n",
       "  'Location_ID_2203900.0': 0.012355934,\n",
       "  'Location_ID_2203950.0': 0.0006931322,\n",
       "  'Location_ID_2203960.0': 0.0,\n",
       "  'Location_ID_2204037.0': 0.0008906757,\n",
       "  'Location_ID_2207135.0': 0.0015330239,\n",
       "  'Location_ID_2207160.0': 0.0012781703,\n",
       "  'Location_ID_2208450.0': 0.0011497508,\n",
       "  'Location_ID_2208493.0': 0.0010467009,\n",
       "  'Location_ID_2336120.0': 0.041256588,\n",
       "  'Location_ID_2336152.0': 0.0,\n",
       "  'Location_ID_23362095.0': 0.004224851,\n",
       "  'Location_ID_2336240.0': 0.0013722576,\n",
       "  'Location_ID_2336300.0': 0.0010252317,\n",
       "  'Location_ID_2336313.0': 0.006556982,\n",
       "  'Location_ID_2336340.0': 0.0026444653,\n",
       "  'Location_ID_2336360.0': 0.00052932685,\n",
       "  'Location_ID_2336410.0': 0.0021328295,\n",
       "  'Location_ID_2336526.0': 0.001004463,\n",
       "  'Location_ID_2336728.0': 0.00823688,\n",
       "  'Location_ID_2337170.0': 0.0018940078,\n",
       "  'Location_ID_2344630.0': 0.027220692,\n",
       "  'Location_ID_2344673.0': 0.000646505,\n",
       "  'Month_1': 0.0049973447,\n",
       "  'Month_10': 0.0,\n",
       "  'Month_11': 0.015563666,\n",
       "  'Month_12': 0.0012318679,\n",
       "  'Month_2': 0.0051074554,\n",
       "  'Month_3': 0.020299712,\n",
       "  'Month_4': 0.002196372,\n",
       "  'Month_5': 0.0016198446,\n",
       "  'Month_6': 0.0012421006,\n",
       "  'Month_7': 0.0,\n",
       "  'Month_8': 0.002725402,\n",
       "  'Month_9': 0.0010258865,\n",
       "  'Week_1': 0.0,\n",
       "  'Week_10': 0.0016102882,\n",
       "  'Week_11': 0.002678696,\n",
       "  'Week_12': 0.0023902627,\n",
       "  'Week_13': 0.0,\n",
       "  'Week_14': 0.004391816,\n",
       "  'Week_15': 0.0,\n",
       "  'Week_16': 0.0,\n",
       "  'Week_17': 0.0,\n",
       "  'Week_18': 0.00074420223,\n",
       "  'Week_19': 0.0,\n",
       "  'Week_2': 0.0021497589,\n",
       "  'Week_20': 0.0,\n",
       "  'Week_21': 0.0,\n",
       "  'Week_22': 0.0007711516,\n",
       "  'Week_23': 0.00079498754,\n",
       "  'Week_24': 0.0,\n",
       "  'Week_25': 0.0010258242,\n",
       "  'Week_26': 0.0,\n",
       "  'Week_27': 0.0,\n",
       "  'Week_28': 0.0009484863,\n",
       "  'Week_29': 0.0,\n",
       "  'Week_3': 0.0,\n",
       "  'Week_30': 0.019307692,\n",
       "  'Week_31': 0.0,\n",
       "  'Week_32': 0.0,\n",
       "  'Week_33': 0.0,\n",
       "  'Week_34': 0.0016311876,\n",
       "  'Week_35': 0.0,\n",
       "  'Week_36': 0.0015642868,\n",
       "  'Week_37': 0.0,\n",
       "  'Week_38': 0.0003089348,\n",
       "  'Week_39': 0.0,\n",
       "  'Week_4': 0.0032444133,\n",
       "  'Week_40': 0.0008680952,\n",
       "  'Week_41': 0.0,\n",
       "  'Week_42': 0.0,\n",
       "  'Week_43': 0.0,\n",
       "  'Week_44': 0.0,\n",
       "  'Week_45': 0.0,\n",
       "  'Week_46': 0.0,\n",
       "  'Week_47': 0.0,\n",
       "  'Week_48': 0.0,\n",
       "  'Week_49': 0.00069948856,\n",
       "  'Week_5': 0.0059401286,\n",
       "  'Week_50': 0.0,\n",
       "  'Week_51': 0.00039969618,\n",
       "  'Week_52': 0.00312955,\n",
       "  'Week_6': 0.0,\n",
       "  'Week_7': 0.0172819,\n",
       "  'Week_8': 0.0020572653,\n",
       "  'Week_9': 0.0,\n",
       "  'Weekday_0': 0.00034199734,\n",
       "  'Weekday_1': 0.0,\n",
       "  'Weekday_2': 0.0,\n",
       "  'Weekday_3': 0.0,\n",
       "  'Weekday_4': 0.0,\n",
       "  'Weekday_5': 0.0014897352,\n",
       "  'Weekday_6': 0.0,\n",
       "  'Season_Fall': 0.01654033,\n",
       "  'Season_Spring': 0.0017331544,\n",
       "  'Season_Summer': 0.0,\n",
       "  'Season_Winter': 0.0},\n",
       " 'eval_metrics': {'rmse': 0.011108538489025297,\n",
       "  'mape': 0.009454276654948326,\n",
       "  'wmape': 0.009598532079274412,\n",
       "  'wbias': 0.0009475153912440627,\n",
       "  'wuforec': 0.005273023735259236,\n",
       "  'woforec': 0.004325508344015174}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-311",
   "language": "python",
   "name": "py-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
